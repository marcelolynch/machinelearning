{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "autores = ['Calderaro', 'Fonteveccia', 'Pagni', 'VanderKooy', 'Verbitsky']\n",
    "textos = []\n",
    "for autor in autores:\n",
    "    for filename in os.listdir(f'data/autores/{autor}'):\n",
    "        with open(f'data/autores/{autor}/{filename}', 'r', encoding='latin-1') as f:\n",
    "            textos.append((autor, f.read()))\n",
    "\n",
    "            \n",
    "def sanitize(s):\n",
    "    # Sacar todo lo que no es alfanumerico y pasar a minusculas, pero dejando los puntos\n",
    "    s = s.lower()\n",
    "    s = re.sub(r'\\.', 'X', s)\n",
    "    s = re.sub(r'\\W+', ' ', s)\n",
    "    s = re.sub('X', '.', s)\n",
    "    return s\n",
    "\n",
    "textos = [(a, sanitize(t)) for (a,t) in textos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def count_words(s):\n",
    "    return len(s.split(\" \"))\n",
    "\n",
    "def count_patterns(s, patterns):\n",
    "    s = f' {s} '\n",
    "    return sum([s.count(f' {p} ') for p in patterns])\n",
    "    \n",
    "\n",
    "# Cantidad promedio de palabras por oración relativa a la cantidad de palabras de todo el texto.\n",
    "def palabras_por_oracion(t):\n",
    "    oraciones = t.split('.')\n",
    "    return np.mean(list(map(count_words, oraciones))) / count_words(t)\n",
    "\n",
    "# Suma de las frecuencias relativas de las cinco palabras más repetidas\n",
    "def frecuencias_relativas(t, n = 5):\n",
    "    c = Counter(t.split(' '))\n",
    "    total = count_words(t)\n",
    "    return sum(map(lambda x: x[1]/total, c.most_common(n)))\n",
    "    \n",
    "\n",
    "# Cantidad de palabras diferentes en el texto, relativa a la cantidad total de palabras\n",
    "def palabras_diferentes(t):\n",
    "    palabras = t.split(' ')\n",
    "    return len(set(palabras))/len(palabras)\n",
    "   \n",
    "\n",
    "def relative_patterns(patterns):\n",
    "    return lambda s: count_patterns(s, patterns) / count_words(s)\n",
    "\n",
    "# Cantidad de Conjunciones subordinantes\n",
    "subordinantes = [\"porque\",\"pues\",\"ya que\",\"puesto que\",\"a causa de\",\"debido a\",\"luego\",\"conque\",\"así que\", \"si\",\"para que\",\"a fin de que\",\"como\",\"que\",\"aunque\",\"aun cuando\",\"si bien\"]\n",
    "conjunciones_subordinantes = relative_patterns(subordinantes)\n",
    "\n",
    "# Cantidad de Conjunciones coordinantes\n",
    "coordinantes = [\"ni\", \"y\", \"o\", \"o bien\", \"pero\", \"aunque\", \"no obstante\", \"sin embargo\", \"sino\", \"por el contrario\"]\n",
    "conjunciones_coordinantes = relative_patterns(coordinantes)\n",
    "\n",
    "# Cantidad de articulos determinados\n",
    "determinados = [\"la\", \"el\", \"los\", \"las\"]\n",
    "articulos_determinados = relative_patterns(determinados)\n",
    "\n",
    "# Cantidad de articulos indeterminados\n",
    "indeterminados = [\"un\", \"una\", \"unos\", \"unas\"]\n",
    "articulos_indeterminados = relative_patterns(indeterminados)\n",
    "\n",
    "# Cantidad de palabras terminadas en \"mente\"\n",
    "def terminan_mente(t):\n",
    "    return len(list(filter(lambda x: re.match(r'.+mente', x), t.split(' ')))) / count_words(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformar textos en atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos los atributos que queremos sacar\n",
    "# aca se pueden comentar lo qeu no nos interesan\n",
    "features_selected = [palabras_por_oracion, \n",
    "                     frecuencias_relativas,\n",
    "                     palabras_diferentes,\n",
    "                     conjunciones_subordinantes,\n",
    "                     conjunciones_coordinantes,\n",
    "                     articulos_determinados,\n",
    "                     articulos_indeterminados,\n",
    "                     terminan_mente\n",
    "                    ]\n",
    "\n",
    "def transform(t):\n",
    "    return [f(t) for f in features_selected]\n",
    "\n",
    "    \n",
    "textos_transformed = [(a, transform(t)) for (a,t) in textos]\n",
    "\n",
    "# X tiene la representacion de los textos, y tiene los autores\n",
    "X = [p[1] for p in textos_transformed]\n",
    "y = [p[0] for p in textos_transformed]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Medias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>,\n",
      "            {0: ['Calderaro',\n",
      "                 'Calderaro',\n",
      "                 'Calderaro',\n",
      "                 'Calderaro',\n",
      "                 'Calderaro',\n",
      "                 'Fonteveccia',\n",
      "                 'Pagni',\n",
      "                 'Pagni',\n",
      "                 'Pagni',\n",
      "                 'Pagni',\n",
      "                 'Pagni',\n",
      "                 'Pagni'],\n",
      "             1: ['Calderaro', 'Fonteveccia', 'Fonteveccia', 'Fonteveccia'],\n",
      "             2: ['Fonteveccia',\n",
      "                 'Fonteveccia',\n",
      "                 'Pagni',\n",
      "                 'Verbitsky',\n",
      "                 'Verbitsky',\n",
      "                 'Verbitsky',\n",
      "                 'Verbitsky',\n",
      "                 'Verbitsky'],\n",
      "             3: ['Calderaro',\n",
      "                 'Calderaro',\n",
      "                 'Calderaro',\n",
      "                 'Calderaro',\n",
      "                 'Calderaro',\n",
      "                 'Fonteveccia',\n",
      "                 'Fonteveccia',\n",
      "                 'Fonteveccia',\n",
      "                 'Fonteveccia',\n",
      "                 'Pagni',\n",
      "                 'Pagni',\n",
      "                 'Verbitsky'],\n",
      "             4: ['Calderaro',\n",
      "                 'Pagni',\n",
      "                 'VanderKooy',\n",
      "                 'VanderKooy',\n",
      "                 'VanderKooy',\n",
      "                 'VanderKooy',\n",
      "                 'VanderKooy',\n",
      "                 'VanderKooy',\n",
      "                 'VanderKooy',\n",
      "                 'VanderKooy',\n",
      "                 'VanderKooy',\n",
      "                 'VanderKooy',\n",
      "                 'Verbitsky',\n",
      "                 'Verbitsky',\n",
      "                 'Verbitsky',\n",
      "                 'Verbitsky']})\n",
      "defaultdict(<class 'list'>,\n",
      "            {'Calderaro': [3, 3, 3, 0, 0, 4, 0, 0, 3, 3, 1, 0],\n",
      "             'Fonteveccia': [0, 3, 3, 3, 2, 1, 3, 1, 1, 2],\n",
      "             'Pagni': [0, 4, 0, 2, 0, 0, 3, 3, 0, 0],\n",
      "             'VanderKooy': [4, 4, 4, 4, 4, 4, 4, 4, 4, 4],\n",
      "             'Verbitsky': [2, 3, 4, 2, 4, 4, 4, 2, 2, 2]})\n"
     ]
    }
   ],
   "source": [
    "from kmeans import kmeans\n",
    "from collections import defaultdict\n",
    "import pprint\n",
    "\n",
    "clustered = kmeans(textos_transformed, 5, vector_sel = lambda x: x[1])\n",
    "\n",
    "groups = defaultdict(list)\n",
    "classifications = defaultdict(list)\n",
    "for c in clustered:\n",
    "    groups[c[1]].append(c[0][0])\n",
    "    classifications[c[0][0]].append(c[1])\n",
    "\n",
    "pprint.pprint(groups)\n",
    "pprint.pprint(classifications)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kohonen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kohonen import Kohonen, neighborhood_linear, linear_decay\n",
    "\n",
    "kc = Kohonen()\n",
    "\n",
    "\n",
    "kc.fit(X, \n",
    "       dim = 4, \n",
    "       epochs = 1000, \n",
    "       alpha = linear_decay(0.1, 1000), \n",
    "       neighborhood = neighborhood_linear(3, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'Calderaro': [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8],\n",
       "             'Fonteveccia': [8, 8, 8, 8, 14, 14, 8, 8, 14, 8],\n",
       "             'Pagni': [8, 8, 8, 8, 8, 8, 8, 8, 8, 8],\n",
       "             'VanderKooy': [8, 8, 8, 8, 8, 8, 8, 8, 8, 8],\n",
       "             'Verbitsky': [8, 8, 8, 8, 8, 8, 8, 14, 8, 8]})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = [kc.predict(x) for x in X]\n",
    "\n",
    "\n",
    "classifications = defaultdict(list)\n",
    "for c in zip(y, classes):\n",
    "    classifications[c[0]].append(c[1])\n",
    "\n",
    "classifications"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
